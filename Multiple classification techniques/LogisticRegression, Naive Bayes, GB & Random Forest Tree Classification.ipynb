{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model to get model performance\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark regression algos</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x224316d9e20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('pyspark regression algos').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('diabetes.csv', header = True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# its a sql df\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: string (nullable = true)\n",
      " |-- Glucose: string (nullable = true)\n",
      " |-- BloodPressure: string (nullable = true)\n",
      " |-- SkinThickness: string (nullable = true)\n",
      " |-- Insulin: string (nullable = true)\n",
      " |-- BMI: string (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Outcome: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to get info on the df\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "|summary|       Pregnancies|          Glucose|     BloodPressure|     SkinThickness|           Insulin|               BMI|DiabetesPedigreeFunction|               Age|           Outcome|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "|  count|               768|              768|               768|               768|               768|               768|                     768|               768|               768|\n",
      "|   mean|3.8450520833333335|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.992578124999977|      0.4718763020833327|33.240885416666664|0.3489583333333333|\n",
      "| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803| 7.884160320375441|       0.331328595012775|11.760231540678689| 0.476951377242799|\n",
      "|    min|                 0|                0|                 0|                 0|                 0|                 0|                   0.078|                21|                 0|\n",
      "|    max|                 9|               99|                98|                99|                99|              67.1|                    2.42|                81|                 1|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+------------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age',\n",
       " 'Outcome']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to apply sql queries\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies\n",
      "Glucose\n",
      "BloodPressure\n",
      "SkinThickness\n",
      "Insulin\n",
      "BMI\n",
      "DiabetesPedigreeFunction\n",
      "Age\n",
      "Outcome\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'Pregnancies'>\n",
      "Column<'Glucose'>\n",
      "Column<'BloodPressure'>\n",
      "Column<'SkinThickness'>\n",
      "Column<'Insulin'>\n",
      "Column<'BMI'>\n",
      "Column<'DiabetesPedigreeFunction'>\n",
      "Column<'Age'>\n",
      "Column<'Outcome'>\n"
     ]
    }
   ],
   "source": [
    "# use to apply functions to column\n",
    "for c in df.columns:\n",
    "    print(col(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "|          6|    148|           72|           35|      0|33.6|                   0.627| 50|      1|\n",
      "|          1|     85|           66|           29|      0|26.6|                   0.351| 31|      0|\n",
      "|          8|    183|           64|            0|      0|23.3|                   0.672| 32|      1|\n",
      "|          1|     89|           66|           23|     94|28.1|                   0.167| 21|      0|\n",
      "|          0|    137|           40|           35|    168|43.1|                   2.288| 33|      1|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql query\n",
    "df.select(*(col(c) for c in df.columns)).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction| Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "|        6.0|  148.0|         72.0|         35.0|    0.0|33.6|                   0.627|50.0|    1.0|\n",
      "|        1.0|   85.0|         66.0|         29.0|    0.0|26.6|                   0.351|31.0|    0.0|\n",
      "|        8.0|  183.0|         64.0|          0.0|    0.0|23.3|                   0.672|32.0|    1.0|\n",
      "|        1.0|   89.0|         66.0|         23.0|   94.0|28.1|                   0.167|21.0|    0.0|\n",
      "|        0.0|  137.0|         40.0|         35.0|  168.0|43.1|                   2.288|33.0|    1.0|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*(col(c).cast('float') for c in df.columns)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction| Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "|        6.0|  148.0|         72.0|         35.0|    0.0|33.6|                   0.627|50.0|    1.0|\n",
      "|        1.0|   85.0|         66.0|         29.0|    0.0|26.6|                   0.351|31.0|    0.0|\n",
      "|        8.0|  183.0|         64.0|          0.0|    0.0|23.3|                   0.672|32.0|    1.0|\n",
      "|        1.0|   89.0|         66.0|         23.0|   94.0|28.1|                   0.167|21.0|    0.0|\n",
      "|        0.0|  137.0|         40.0|         35.0|  168.0|43.1|                   2.288|33.0|    1.0|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*(col(c).cast('float').alias(c) for c in df.columns)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction| Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "|        6.0|  148.0|         72.0|         35.0|    0.0|33.6|                   0.627|50.0|    1.0|\n",
      "|        1.0|   85.0|         66.0|         29.0|    0.0|26.6|                   0.351|31.0|    0.0|\n",
      "|        8.0|  183.0|         64.0|          0.0|    0.0|23.3|                   0.672|32.0|    1.0|\n",
      "|        1.0|   89.0|         66.0|         23.0|   94.0|28.1|                   0.167|21.0|    0.0|\n",
      "|        0.0|  137.0|         40.0|         35.0|  168.0|43.1|                   2.288|33.0|    1.0|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formated_df = df.select(*(col(c).cast('float') for c in df.columns))\n",
    "formated_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: float (nullable = true)\n",
      " |-- Glucose: float (nullable = true)\n",
      " |-- BloodPressure: float (nullable = true)\n",
      " |-- SkinThickness: float (nullable = true)\n",
      " |-- Insulin: float (nullable = true)\n",
      " |-- BMI: float (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: float (nullable = true)\n",
      " |-- Age: float (nullable = true)\n",
      " |-- Outcome: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formated_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------------+------------------+------------------+\n",
      "|summary|       Pregnancies|          Glucose|     BloodPressure|     SkinThickness|           Insulin|              BMI|DiabetesPedigreeFunction|               Age|           Outcome|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------------+------------------+------------------+\n",
      "|  count|               768|              768|               768|               768|               768|              768|                     768|               768|               768|\n",
      "|   mean|3.8450520833333335|     120.89453125|       69.10546875|20.536458333333332| 79.79947916666667|31.99257813890775|      0.4718763029280429|33.240885416666664|0.3489583333333333|\n",
      "| stddev|  3.36957806269887|31.97261819513622|19.355807170644777|15.952217567727642|115.24400235133803|7.884160293010772|      0.3313285967924436|11.760231540678689| 0.476951377242799|\n",
      "|    min|               0.0|              0.0|               0.0|               0.0|               0.0|              0.0|                   0.078|              21.0|               0.0|\n",
      "|    max|              17.0|            199.0|             122.0|              99.0|             846.0|             67.1|                    2.42|              81.0|               1.0|\n",
      "+-------+------------------+-----------------+------------------+------------------+------------------+-----------------+------------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formated_df.describe().show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, isnan, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|          0|      0|            0|            0|      0|  0|                       0|  0|      0|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formated_df.select([count(when(isnan(c), c)).alias(c) for c in formated_df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI|DiabetesPedigreeFunction|Age|Outcome|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "|          0|      0|            0|            0|      0|  0|                       0|  0|      0|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formated_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in formated_df.columns]).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = formated_df.drop('Outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction| Age|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+\n",
      "|        6.0|  148.0|         72.0|         35.0|    0.0|33.6|                   0.627|50.0|\n",
      "|        1.0|   85.0|         66.0|         29.0|    0.0|26.6|                   0.351|31.0|\n",
      "|        8.0|  183.0|         64.0|          0.0|    0.0|23.3|                   0.672|32.0|\n",
      "|        1.0|   89.0|         66.0|         23.0|   94.0|28.1|                   0.167|21.0|\n",
      "|        0.0|  137.0|         40.0|         35.0|  168.0|43.1|                   2.288|33.0|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pregnancies',\n",
       " 'Glucose',\n",
       " 'BloodPressure',\n",
       " 'SkinThickness',\n",
       " 'Insulin',\n",
       " 'BMI',\n",
       " 'DiabetesPedigreeFunction',\n",
       " 'Age']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines given list of columns & create a single vector col\n",
    "assembler = VectorAssembler(inputCols= features.columns, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+--------------------+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin| BMI|DiabetesPedigreeFunction| Age|Outcome|            features|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+--------------------+\n",
      "|        6.0|  148.0|         72.0|         35.0|    0.0|33.6|                   0.627|50.0|    1.0|[6.0,148.0,72.0,3...|\n",
      "|        1.0|   85.0|         66.0|         29.0|    0.0|26.6|                   0.351|31.0|    0.0|[1.0,85.0,66.0,29...|\n",
      "|        8.0|  183.0|         64.0|          0.0|    0.0|23.3|                   0.672|32.0|    1.0|[8.0,183.0,64.0,0...|\n",
      "|        1.0|   89.0|         66.0|         23.0|   94.0|28.1|                   0.167|21.0|    0.0|[1.0,89.0,66.0,23...|\n",
      "|        0.0|  137.0|         40.0|         35.0|  168.0|43.1|                   2.288|33.0|    1.0|[0.0,137.0,40.0,3...|\n",
      "+-----------+-------+-------------+-------------+-------+----+------------------------+----+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(formated_df)\n",
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|Outcome|\n",
      "+--------------------+-------+\n",
      "|[6.0,148.0,72.0,3...|    1.0|\n",
      "|[1.0,85.0,66.0,29...|    0.0|\n",
      "|[8.0,183.0,64.0,0...|    1.0|\n",
      "|[1.0,89.0,66.0,23...|    0.0|\n",
      "|[0.0,137.0,40.0,3...|    1.0|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select('features', 'Outcome').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+-------+\n",
      "|features                                                              |Outcome|\n",
      "+----------------------------------------------------------------------+-------+\n",
      "|[6.0,148.0,72.0,35.0,0.0,33.599998474121094,0.6269999742507935,50.0]  |1.0    |\n",
      "|[1.0,85.0,66.0,29.0,0.0,26.600000381469727,0.35100001096725464,31.0]  |0.0    |\n",
      "|[8.0,183.0,64.0,0.0,0.0,23.299999237060547,0.671999990940094,32.0]    |1.0    |\n",
      "|[1.0,89.0,66.0,23.0,94.0,28.100000381469727,0.16699999570846558,21.0] |0.0    |\n",
      "|[0.0,137.0,40.0,35.0,168.0,43.099998474121094,2.2880001068115234,33.0]|1.0    |\n",
      "+----------------------------------------------------------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.select('features','Outcome').show(5, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|Outcome|\n",
      "+--------------------+-------+\n",
      "|[6.0,148.0,72.0,3...|    1.0|\n",
      "|[1.0,85.0,66.0,29...|    0.0|\n",
      "|[8.0,183.0,64.0,0...|    1.0|\n",
      "|[1.0,89.0,66.0,23...|    0.0|\n",
      "|[0.0,137.0,40.0,3...|    1.0|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembled_df = output.select('features', 'Outcome')\n",
    "assembled_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scalar = StandardScaler().setInputCol('features').setOutputCol('scaled_features')\n",
    "std_scaled_df = std_scalar.fit(assembled_df).transform(assembled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+\n",
      "|            features|Outcome|     scaled_features|\n",
      "+--------------------+-------+--------------------+\n",
      "|[6.0,148.0,72.0,3...|    1.0|[1.78063837321943...|\n",
      "|[1.0,85.0,66.0,29...|    0.0|[0.29677306220323...|\n",
      "|[8.0,183.0,64.0,0...|    1.0|[2.37418449762590...|\n",
      "|[1.0,89.0,66.0,23...|    0.0|[0.29677306220323...|\n",
      "|[0.0,137.0,40.0,3...|    1.0|[0.0,4.2849165233...|\n",
      "+--------------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "std_scaled_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|scaled_features                                                                                                                                        |Outcome|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "|[1.7806383732194306,4.628960915766174,3.7198138711154307,2.1940523222807116,0.0,4.261709202425419,1.8923810993699686,4.251616970894646]                |1.0    |\n",
      "|[0.29677306220323846,2.658524850271114,3.4098293818558116,1.8179290670325896,0.0,3.373853320188119,1.0593713140527197,2.6360025219546803]              |0.0    |\n",
      "|[2.3741844976259077,5.723647618818986,3.306501218769272,0.0,0.0,2.955292430788826,2.028197980632078,2.721034861372573]                                 |1.0    |\n",
      "|[0.29677306220323846,2.783631902048578,3.4098293818558116,1.4418058117844677,0.8156606685129459,3.564108203936454,0.5040313372439763,1.785679127775751]|0.0    |\n",
      "|[0.0,4.284916523378148,2.0665632617307947,2.1940523222807116,1.4577765139380312,5.466656799498205,6.905531635244907,2.806067200790466]                 |1.0    |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df = std_scaled_df.select('scaled_features', 'Outcome')\n",
    "scaled_df.show(5, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|     scaled_features|Outcome|\n",
      "+--------------------+-------+\n",
      "|[1.78063837321943...|    1.0|\n",
      "|[0.29677306220323...|    0.0|\n",
      "|[2.37418449762590...|    1.0|\n",
      "|[0.29677306220323...|    0.0|\n",
      "|[0.0,4.2849165233...|    1.0|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = scaled_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|     scaled_features|Outcome|\n",
      "+--------------------+-------+\n",
      "|(8,[0,1,6,7],[0.5...|    0.0|\n",
      "|(8,[0,1,6,7],[0.5...|    0.0|\n",
      "|(8,[0,1,6,7],[0.8...|    0.0|\n",
      "|(8,[0,1,6,7],[1.7...|    0.0|\n",
      "|(8,[0,1,6,7],[2.0...|    0.0|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|     scaled_features|Outcome|\n",
      "+--------------------+-------+\n",
      "|(8,[1,5,6,7],[2.2...|    0.0|\n",
      "|(8,[1,5,6,7],[3.6...|    0.0|\n",
      "|(8,[1,5,6,7],[4.4...|    1.0|\n",
      "|[0.0,1.7827754878...|    0.0|\n",
      "|[0.0,2.4395875096...|    0.0|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol = 'scaled_features', labelCol = 'Outcome')\n",
    "log_reg_model = log_reg.fit(train_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|     scaled_features|Outcome|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|(8,[1,5,6,7],[2.2...|    0.0|[2.97837073156098...|[0.95158736795904...|       0.0|\n",
      "|(8,[1,5,6,7],[3.6...|    0.0|[-1.1548579069412...|[0.23960288546272...|       1.0|\n",
      "|(8,[1,5,6,7],[4.4...|    1.0|[-1.6333032972623...|[0.16337834497809...|       1.0|\n",
      "|[0.0,1.7827754878...|    0.0|[2.70422281555887...|[0.93727536325253...|       0.0|\n",
      "|[0.0,2.4395875096...|    0.0|[2.59081446275094...|[0.93026806934250...|       0.0|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg_predictions = log_reg_model.transform(test_df)\n",
    "log_reg_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|Outcome|prediction|\n",
      "+-------+----------+\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       1.0|\n",
      "|    1.0|       1.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    0.0|       0.0|\n",
      "|    1.0|       0.0|\n",
      "+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg_predictions.select('Outcome','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_and_Labels = log_reg_predictions.select(\"Outcome\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=0.0),\n",
       " Row(Outcome=0.0, prediction=0.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0),\n",
       " Row(Outcome=1.0, prediction=1.0)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_and_Labels.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7743362831858407\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_LR = evaluator.evaluate(log_reg_predictions)\n",
    "print (\"Accuracy = \" ,accuracy_LR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = NaiveBayes(featuresCol='scaled_features', labelCol='Outcome', smoothing=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|     scaled_features|Outcome|\n",
      "+--------------------+-------+\n",
      "|(8,[0,1,6,7],[0.5...|    0.0|\n",
      "|(8,[0,1,6,7],[0.5...|    0.0|\n",
      "|(8,[0,1,6,7],[0.8...|    0.0|\n",
      "|(8,[0,1,6,7],[1.7...|    0.0|\n",
      "|(8,[0,1,6,7],[2.0...|    0.0|\n",
      "+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bay_model = naive_bayes.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|     scaled_features|Outcome|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|(8,[1,5,6,7],[2.2...|    0.0|[-14.971394413191...|[0.58828421632891...|       0.0|\n",
      "|(8,[1,5,6,7],[3.6...|    0.0|[-27.396299066735...|[0.52876773863154...|       0.0|\n",
      "|(8,[1,5,6,7],[4.4...|    1.0|[-22.122620098002...|[0.57101956248266...|       0.0|\n",
      "|[0.0,1.7827754878...|    0.0|[-29.085690086716...|[0.68655152631738...|       0.0|\n",
      "|[0.0,2.4395875096...|    0.0|[-31.747249850470...|[0.74141771024924...|       0.0|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_prediction = naive_bay_model.transform(test_df)\n",
    "naive_prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels = naive_prediction.select(\"Outcome\",\"prediction\").rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_NB = evaluator.evaluate(naive_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6769911504424779\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy\",accuracy_NB)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boost_class = GBTClassifier(labelCol=\"Outcome\", featuresCol=\"scaled_features\")\n",
    "gradient_boost_model = gradient_boost_class.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_prediction = gradient_boost_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|     scaled_features|Outcome|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|(8,[1,5,6,7],[2.2...|    0.0|[1.52974106441609...|[0.95519013628407...|       0.0|\n",
      "|(8,[1,5,6,7],[3.6...|    0.0|[-0.5882999410465...|[0.23566409712830...|       1.0|\n",
      "|(8,[1,5,6,7],[4.4...|    1.0|[-1.7976180774408...|[0.02672060613007...|       1.0|\n",
      "|[0.0,1.7827754878...|    0.0|[0.81650635454177...|[0.83658193184099...|       0.0|\n",
      "|[0.0,2.4395875096...|    0.0|[1.13943442722664...|[0.90711178044169...|       0.0|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator( labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_GBT = evaluator.evaluate(gbt_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.6858407079646017\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy\",accuracy_GBT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|     scaled_features|Outcome|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "|(8,[1,5,6,7],[2.2...|    0.0|[35.9580531440866...|[0.89895132860216...|       0.0|\n",
      "|(8,[1,5,6,7],[3.6...|    0.0|[15.1580659672269...|[0.37895164918067...|       1.0|\n",
      "|(8,[1,5,6,7],[4.4...|    1.0|[13.4013064307224...|[0.33503266076806...|       1.0|\n",
      "|[0.0,1.7827754878...|    0.0|[33.0300483162224...|[0.82575120790556...|       0.0|\n",
      "|[0.0,2.4395875096...|    0.0|[34.2878340303959...|[0.85719585075989...|       0.0|\n",
      "+--------------------+-------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_classifier = RandomForestClassifier(labelCol=\"Outcome\", featuresCol=\"scaled_features\", numTrees=40)\n",
    "rf_model = random_forest_classifier.fit(train_df)\n",
    "rf_prediction = rf_model.transform(test_df)\n",
    "rf_prediction.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator( labelCol=\"Outcome\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy_RF= evaluator.evaluate(rf_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7522123893805309\n"
     ]
    }
   ],
   "source": [
    "print (\"Accuracy\",accuracy_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
